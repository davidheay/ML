{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caeb5e37-807e-484e-8092-ef1184da9de6",
   "metadata": {},
   "source": [
    "## Estid Lozano\n",
    "## David Herrera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2742c1-0ea8-47ad-a745-2588558a6f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adcc7cc-b34b-414a-9849-359f69f4faf2",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5478bf5e-666e-422a-9527-a3fe2b8f4dcb",
   "metadata": {},
   "source": [
    "**1.1.** Write a function **decode_image_dataset(X, size, channels)** that takes a numpy array **X** with *n* rows and returns a numpy array of shape *n x size x size x channels*.\n",
    "Assume that within **X** the first *size x size* attributes are for the first channel, the second *size x size* attributes for the second channel, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4e2894-f7dc-4385-8e7c-737e8c565ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image_dataset(X, size, channels):\n",
    "    X_decoded = X.reshape((len(X), size, size, channels), order='F')\n",
    "    return np.transpose(X_decoded, (0, 2, 1, 3)) # Rotates the img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5a0b2a-1bae-4567-90f5-8b07f35796fd",
   "metadata": {},
   "source": [
    "**1.2.** Load the **imgds.csv** dataset and visualize some of the images together with their label (check the imshow function of matplotlib)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c58cd2-acd5-420f-8234-602452555c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"imgds.csv\").to_numpy()\n",
    "y, X = X[:, -1], X[:, :-1]\n",
    "img_size = int(math.sqrt(X.shape[1] / 3))\n",
    "y_onehot = to_categorical(y)\n",
    "X_decoded = decode_image_dataset(X, img_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44267484-502a-470d-a9fb-a94b73d70b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols, figsize, = 2, 5, 12\n",
    "plt.figure(figsize=(figsize, figsize * rows / cols))\n",
    "for i, x in enumerate(X_decoded[:rows * cols]):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.title(\"label: \" + str(y[i]))\n",
    "    plt.imshow(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06933a42-f04f-42b6-b695-3e1b616f6f0b",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54b399c-8d1a-4a21-8d47-bfc86fb21448",
   "metadata": {},
   "source": [
    "We now work with the imgds dataset, which is a ten class classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84419ed4-86b0-4489-9dd3-dbf085ce0778",
   "metadata": {},
   "source": [
    "**2.1.** Create fully connected networks in Keras, and train them on the original unformatted data. Try 1 to 10 hidden layers with between 10, 20, 30, ..., 100 neurons, i.e. 100 architectures in total. Use a softmax function in the last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2058c5-5458-40ed-ba02-d4886f78ff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2)\n",
    "\n",
    "# setup and save models in tuples (model, num_layers, units_per_layer)\n",
    "models = [(\n",
    "    keras.Sequential(\n",
    "        [Dense(n_unit, activation='relu', input_dim=X.shape[1])]\n",
    "        + [Dense(n_unit, activation='relu') for i in range(n_layer - 1)] +\n",
    "        [Dense(10, activation='softmax')]\n",
    "    ),\n",
    "    n_layer, n_unit,\n",
    ") for n_layer in range(1, 11) for n_unit in range(10, 110, 10)]\n",
    "\n",
    "for model in models:\n",
    "    model[0].compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e195e9-ceed-4911-bb1e-3c6527e74d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model[0].fit(X_train, y_train, epochs=1, batch_size=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6091e88c-4141-44d6-9b23-51834dba3b59",
   "metadata": {},
   "source": [
    "Create a matrix with performances and show them in a heat map (imshow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5385a7e-0057-4a29-a241-9684222a9e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b64caf3-55d2-4c58-be31-efa8d1f8e545",
   "metadata": {},
   "source": [
    "**2.2.** Create convolutional networks in Keras, and train them on the formatted data. Use at least one dense layer prior to the output layer. Check out the **Flatten** layer to convert the output of a convolutional layer into a vector-based representation necessary for the dense layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0dab0a-3a1b-4f87-adc5-905376b8475e",
   "metadata": {},
   "source": [
    "Try the combinations of the following configurations:\n",
    "<div style=\"margin-left: 1em;\">\n",
    "a) numbers of 2D convolutional layers between 1 and 5 (we do not convolve in 3D here, but apply 2D convolutions over each of the color channels). <br/>\n",
    "b) numbers of filters between 1 and 100. <br/>\n",
    "c) window sizes (kernel_size) between 2 and 10. <br/>\n",
    "d) no pooling, avg pooling and max pooling.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86398bd-6565-4d8c-9730-6f57af71ca43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "427fea97-bed7-4ecc-8be2-1aed44188d7d",
   "metadata": {},
   "source": [
    "Report your results graphically and draw a conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62f01ae-a072-484a-a57a-1f9d88076da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ec62d6f-b966-4543-8882-d3c5e1e51ab6",
   "metadata": {},
   "source": [
    "Conclusion:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
