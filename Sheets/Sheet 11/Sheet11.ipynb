{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caeb5e37-807e-484e-8092-ef1184da9de6",
   "metadata": {},
   "source": [
    "## Estid Lozano\n",
    "## David Herrera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2742c1-0ea8-47ad-a745-2588558a6f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adcc7cc-b34b-414a-9849-359f69f4faf2",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5478bf5e-666e-422a-9527-a3fe2b8f4dcb",
   "metadata": {},
   "source": [
    "**1.1.** Write a function **decode_image_dataset(X, size, channels)** that takes a numpy array **X** with *n* rows and returns a numpy array of shape *n x size x size x channels*.\n",
    "Assume that within **X** the first *size x size* attributes are for the first channel, the second *size x size* attributes for the second channel, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4e2894-f7dc-4385-8e7c-737e8c565ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image_dataset(X, size, channels):\n",
    "    X_decoded = X.reshape((len(X), size, size, channels), order='F')\n",
    "    return np.transpose(X_decoded, (0, 2, 1, 3)) # Rotates the img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5a0b2a-1bae-4567-90f5-8b07f35796fd",
   "metadata": {},
   "source": [
    "**1.2.** Load the **imgds.csv** dataset and visualize some of the images together with their label (check the imshow function of matplotlib)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c58cd2-acd5-420f-8234-602452555c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"imgds.csv\").to_numpy()\n",
    "y, X = X[:, -1], X[:, :-1]\n",
    "img_size = int(math.sqrt(X.shape[1] / 3))\n",
    "y_onehot = to_categorical(y)\n",
    "X_decoded = decode_image_dataset(X, img_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44267484-502a-470d-a9fb-a94b73d70b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols, figsize, = 2, 5, 12\n",
    "plt.figure(figsize=(figsize, figsize * rows / cols))\n",
    "for i, x in enumerate(X_decoded[:rows * cols]):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.title(\"label: \" + str(y[i]))\n",
    "    plt.imshow(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06933a42-f04f-42b6-b695-3e1b616f6f0b",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54b399c-8d1a-4a21-8d47-bfc86fb21448",
   "metadata": {},
   "source": [
    "We now work with the imgds dataset, which is a ten class classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84419ed4-86b0-4489-9dd3-dbf085ce0778",
   "metadata": {},
   "source": [
    "**2.1.** Create fully connected networks in Keras, and train them on the original unformatted data. Try 1 to 10 hidden layers with between 10, 20, 30, ..., 100 neurons, i.e. 100 architectures in total. Use a softmax function in the last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2058c5-5458-40ed-ba02-d4886f78ff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2)\n",
    "\n",
    "# setup and save models in tuples (model, num_layers, units_per_layer)\n",
    "layerss = range(1, 11)\n",
    "units = range(10, 110, 10)\n",
    "modelsList = [(\n",
    "    keras.Sequential(\n",
    "        [layers.Dense(n_unit, activation='relu', input_dim=X.shape[1])]\n",
    "        + [layers.Dense(n_unit, activation='relu') for i in range(n_layer - 1)] +\n",
    "        [layers.Dense(10, activation='softmax')]\n",
    "    ),\n",
    "    n_layer, n_unit\n",
    ") for n_layer in layerss for n_unit in units]\n",
    "\n",
    "for model in modelsList:\n",
    "    model[0].compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6091e88c-4141-44d6-9b23-51834dba3b59",
   "metadata": {},
   "source": [
    "Create a matrix with performances and show them in a heat map (imshow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e195e9-ceed-4911-bb1e-3c6527e74d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.zeros((len(layerss),len(units)))\n",
    "for model in modelsList:\n",
    "    acc[model[1]-1][int((model[2]/10)-1)] = model[0].fit(X_train, y_train, epochs=10, batch_size=50, validation_data=(X_test, y_test)).history['accuracy'][-1]\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(acc)\n",
    "cbar = ax.figure.colorbar(im, ax=ax)\n",
    "cbar.ax.set_ylabel(\"accuracy\", rotation=-90, va=\"bottom\")\n",
    "ax.set_xticks(np.arange(acc.shape[1]))\n",
    "ax.set_yticks(np.arange(acc.shape[0]))\n",
    "ax.set_xlabel(\"layers\")\n",
    "ax.set_xticklabels(layerss)\n",
    "ax.set_ylabel(\"units\")\n",
    "ax.set_yticklabels(units)\n",
    "for i in range(acc.shape[0]):\n",
    "    for j in range(acc.shape[1]):\n",
    "        text = ax.text(j, i, acc[i, j],ha=\"center\", va=\"center\", color=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b64caf3-55d2-4c58-be31-efa8d1f8e545",
   "metadata": {},
   "source": [
    "**2.2.** Create convolutional networks in Keras, and train them on the formatted data. Use at least one dense layer prior to the output layer. Check out the **Flatten** layer to convert the output of a convolutional layer into a vector-based representation necessary for the dense layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0dab0a-3a1b-4f87-adc5-905376b8475e",
   "metadata": {},
   "source": [
    "Try the combinations of the following configurations:\n",
    "<div style=\"margin-left: 1em;\">\n",
    "a) numbers of 2D convolutional layers between 1 and 5 (we do not convolve in 3D here, but apply 2D convolutions over each of the color channels). <br/>\n",
    "b) numbers of filters between 1 and 100. <br/>\n",
    "c) window sizes (kernel_size) between 2 and 10. <br/>\n",
    "d) no pooling, avg pooling and max pooling.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86398bd-6565-4d8c-9730-6f57af71ca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y,img_size,modelsList\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_decoded, y_onehot, test_size=0.2)\n",
    "del y_onehot, X_decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427fea97-bed7-4ecc-8be2-1aed44188d7d",
   "metadata": {},
   "source": [
    "Report your results graphically and draw a conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62f01ae-a072-484a-a57a-1f9d88076da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create models\n",
    "\n",
    "#variables\n",
    "convulationalLayers = list(range(1,5))\n",
    "filters = [int(round((100**(1/9.0))**i)) for i in range(10)]\n",
    "kernelSizes = list(range(2,10))\n",
    "poolings= [None,layers.MaxPooling2D,layers.AveragePooling2D]\n",
    "\n",
    "\n",
    "modelsList = []\n",
    "for conLayer in convulationalLayers:\n",
    "    for fil in filters:\n",
    "        for kerSize in kernelSizes:\n",
    "            for pool in poolings:\n",
    "                model = models.Sequential()\n",
    "                n = 32\n",
    "                for i in range(conLayer):\n",
    "                    if i == 0:\n",
    "                        model.add(layers.Conv2D(fil, (kerSize, kerSize), activation='relu', input_shape=(32, 32, 3)))\n",
    "                        n = n - kerSize +1\n",
    "                        if pool:\n",
    "                            model.add(pool((kerSize, kerSize)))\n",
    "                            n = n /kerSize\n",
    "                    else:\n",
    "                        if n - kerSize +1>1:\n",
    "                            model.add(layers.Conv2D(fil, (kerSize, kerSize), activation='relu'))\n",
    "                            n = n - kerSize +1\n",
    "                            if pool:\n",
    "                                if n /kerSize>1:\n",
    "                                    model.add(pool((kerSize, kerSize)))\n",
    "                                    n =n /kerSize\n",
    "                model.add(layers.Flatten())\n",
    "                model.add(layers.Dense(10, activation='softmax'))\n",
    "                model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "                modelsList.append({'model':model,'title': 'ConvLayers:'+str(conLayer)+', filters:'+ str(fil)+',kernelSize:'+ str(kerSize)+\",pooltype:\"+ str(pool) })\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27adf013-7df7-4fc4-9f08-d5b8fa3170a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxAccuracy = [0,'None']\n",
    "plt.figure(figsize=(12, 10), dpi=80)\n",
    "for model in modelsList:\n",
    "    print('training:'+model[\"title\"])\n",
    "    history =  model['model'].fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "    plt.plot(history.history['accuracy'], label=model['title'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend(loc='lower right')\n",
    "    if history.history['accuracy'][-1]>maxAccuracy[0]:\n",
    "        maxAccuracy[0] = history.history['accuracy'][-1]\n",
    "        maxAccuracy[1] = model['title']\n",
    "print('bestModel',maxAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27adf013-7df7-4fc4-9f08-d5b8fa3170a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best structure found\n",
    "\n",
    "model = models.Sequential()\n",
    "# 160 = 32 * 5\n",
    "model.add(layers.Conv2D(160, (2, 2), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(160, (2, 2), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(160, (2, 2), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history =  model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec62d6f-b966-4543-8882-d3c5e1e51ab6",
   "metadata": {},
   "source": [
    "Conclusion: Through different combinations we found that the best kernelSize was 2, on the other hand 2 and 3 layers present a very good result, with a MaxPooloing, with 96,128 or 160 filters\n",
    "\n",
    "These were the results found:\n",
    "\n",
    "* ConvLayers:2, filters:96,kernelSize:2,MaxPooling2D\n",
    "accuracy:0.645312488079071\n",
    "* ConvLayers:2, filters:128,kernelSize:2,MaxPooling2D\n",
    "accuracy:0.6386874914169312\n",
    "* ConvLayers:2, filters:160,kernelSize:2,MaxPooling2D\n",
    "accuracy:0.6569374799728394\n",
    "\n",
    "* ConvLayers:3, filters:96,kernelSize:2,MaxPooling2D\n",
    "accuracy:0.6629375219345093\n",
    "* ConvLayers:3, filters:128,kernelSize:2,MaxPooling2D\n",
    "accuracy:0.692354142665863\n",
    "* ConvLayers:3, filters:160,kernelSize:2,MaxPooling2D\n",
    "accuracy:0.7023749947547913\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
