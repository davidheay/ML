{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd02ba9a-d1e8-43a3-8dce-86918e4829dc",
   "metadata": {},
   "source": [
    "### Estid Lozano\n",
    "### David Herrera\n",
    "### Nicolas Gonzalez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc07d57c-d6da-4d19-8da1-16cc2bb1d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import openml as oml\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import preprocessing\n",
    "# from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5c3d47-bedf-4c1f-884c-c25b4e820991",
   "metadata": {},
   "source": [
    "# Exercise 1 (Up-Sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73c92fe-7d0a-4393-996e-3f61c78d8d5a",
   "metadata": {},
   "source": [
    "Hint: You might want to have a look at the imblearn.over_sampling package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593d7c41-2fb5-49c1-b271-9f316739cc58",
   "metadata": {},
   "source": [
    "**1.1.** write a function visualize_data(df, class_att) that receives a dataframe with three columns (the one named class_att is the label column) and creates two plots: One shows a scatter plot of the data in the first two attributes. The second shows a bar-chart with the class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ed2a44-4988-472e-ac2e-f1ceb6e01f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(df, class_att, dfUp = None):\n",
    "    \"\"\"\n",
    "    grouped = df.groupby(class_att)\n",
    "    labels = df[class_att].unique()\n",
    "    colors = dict(zip(labels, [\"#d22\", \"#2d2\", \"#22d\", \"#dd2\", \"#d2d\", \"#2dd\"][:len(labels)]))\n",
    "    if ax == None:\n",
    "        fig, ax = plt.subplots()\n",
    "    for key, group in grouped:\n",
    "        group.plot(ax=ax, kind='scatter', x=df.columns[0], y=df.columns[1], label=key, color=colors[key])\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    df.loc[:,df.columns!=class_att].plot(ax=ax,kind='scatter',x=df.columns[0],y=df.columns[1], label=\"original\")\n",
    "    d2 = df[class_att].value_counts()\n",
    "    if dfUp is not None:\n",
    "        dfUp = dfUp[~dfUp.isin(df)].dropna(how = 'all')\n",
    "        dfUp.loc[:,df.columns!=class_att].plot(ax=ax,kind='scatter',x=dfUp.columns[0],y=dfUp.columns[1],color=\"orange\",label=\"up\")\n",
    "        d2 = pd.concat([d2,dfUp[class_att].value_counts()],axis=1)\n",
    "        d2.columns = [\"original\", \"up\"]\n",
    "    plt.show()\n",
    "    d2.plot(kind=\"bar\",title=class_att)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb9e7f6-0dea-4d11-a6f2-e1624dcc1a9d",
   "metadata": {},
   "source": [
    "**1.2.** Load the rmftsa_sleepdata dataset from openml.org and visualize it with the above method. Then use the SMOTE method from scikit-learn to up-sample the minority class. Use the above function to plot the data again. Use a different color/symbol for the up-sampled instances.\n",
    "\n",
    "Was the upsampling successful in that it generated reasonable new instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa7013a-6d4e-4670-aeca-8c1ed4bdd338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and visualize\n",
    "dtset = oml.datasets.get_dataset(679) # rmftsa_sleepdata\n",
    "X, y, catInd, attrs = dtset.get_data(\n",
    "    target=dtset.default_target_attribute)\n",
    "df = pd.concat([X,pd.DataFrame({\"label\":y})],axis=1)\n",
    "visualize_data(df, \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcfceb0-84b9-41a4-a035-b0fd8c70e4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smote and visualize\n",
    "XUp, yUp = SMOTE(random_state=0).fit_resample(X, y)\n",
    "dfUp = pd.concat([XUp,pd.DataFrame({\"label\":yUp})],axis=1)\n",
    "visualize_data(df, \"label\", dfUp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4ba336-c0ae-4e3a-add4-ebad678e8a05",
   "metadata": {},
   "source": [
    "**Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caa2773-f389-462b-bc99-d029f384a431",
   "metadata": {},
   "source": [
    "# Exercise 2 (Feature Scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a95611c-9137-4025-879e-7635fa3ca95d",
   "metadata": {},
   "source": [
    "Load the amazon-commerce-reviews dataset (1457). Compare the prediction accuracy (5-fold CV) of a decision tree and logistic regression when using none or any of the feature scaling techniques seen in class.\n",
    "\n",
    "Report the performance of all these combinations. Does feature scaling bring an advantage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be33155-3873-4e99-875f-4ca35c090221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "dtset = oml.datasets.get_dataset(1457) # amazon-commerce-reviews\n",
    "X, y, catInd, attrs = dtset.get_data(\n",
    "    target=dtset.default_target_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d2cd6-6460-4d34-add5-f4d94bf592f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictAndCompare(technique, X):\n",
    "    print(\"Technique:\", technique)\n",
    "    clf = DecisionTreeClassifier(max_leaf_nodes=3, min_samples_split = 5)\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    print(\"DecisionTree error: mean of %0.2f with stand. dev. of %0.2f\"  % (scores.mean(), scores.std()))\n",
    "    clf = LogisticRegression()\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    print(\"LogisticRegresion error: mean of %0.2f with stand. dev. of %0.2f\"  % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8613e008-c0c6-4a5c-9cb7-f70851ca2402",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictAndCompare(\"None\", X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330db654-fe1d-4a6e-ba45-49915bb8f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictAndCompare(\"MinMax\", preprocessing.MinMaxScaler().fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cd2276-eaab-40e9-84a7-f3a7380a7add",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictAndCompare(\"Standard\", preprocessing.StandardScaler().fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe0eec0-4e71-4a3e-863d-fa7fcba6bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictAndCompare(\"Mean\", preprocessing.MinMaxScaler(feature_range=(-1,1)).fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fbe635-3287-4a82-8e4f-bffa46f45916",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictAndCompare(\"Sqrt\", np.sqrt(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d699a3d-2de4-4a4e-a8c0-75ed8a4dbaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictAndCompare(\"Power\", preprocessing.PowerTransformer().fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba04add-b636-4b11-97df-ed35bafae1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictAndCompare(\"Unit-Length\", preprocessing.Normalizer().fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd0395c-53f5-48ab-ac03-7e838e97942a",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f4ceb4-a70b-4031-b8ff-c987e387458d",
   "metadata": {},
   "source": [
    "# Exercise 3 (Feature Extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea2c693-60b5-48cb-a67b-d4a3206245ff",
   "metadata": {},
   "source": [
    "Load the amazon-commerce-reviews dataset. Compare the prediction accuracy (5-fold CV) of a decision tree and logistic regression when using the original against landmark features (using all the (training) datapoints as landmarks).\n",
    "\n",
    "Report the performances. Does landmarking bring an advantage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e7d39f-2ee1-41ff-a1c4-1a15877205ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c2476a8-5281-4cfc-beba-c6dd814973b4",
   "metadata": {},
   "source": [
    "# Exercise 4 (Feature selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3447c961-9013-4867-80b3-1e979b9dc8ae",
   "metadata": {},
   "source": [
    "Load the madelon dataset (1485). Compare the prediction accuracy (5-fold CV) of a decision tree and logistic regression when using none or the sklearn.feature_selection.chi2 or the sklearn.feature_selection.mutual_info_classif\n",
    "criterion.\n",
    "\n",
    "Use different selectors, e.g., SelectKBest, SelectPercentile, and GenericUnivariateSelect with different parameters.\n",
    "\n",
    "Report the performance of all these combinations. Does feature scaling bring an advantage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196f02a-687a-4d12-b017-010a8c029732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
