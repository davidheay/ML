{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Integrantes\r\n",
    "* ### David Herrera\r\n",
    "* ### Estid Lozano\r\n",
    "* ### Nicolás González"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Imports\n",
    "from numbers import Number\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from smlutil import *\n",
    "import itertools\n",
    "from collections import Counter"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**1.1** Suppose that we model, for any instance x, the log-odds ratio between a class i and the distinguished class K as the dot product of a regression vector βi and x, i.e\n",
    "• Show that this is equivalent to saying that\n",
    "• Show that we can also define a vector for class K be setting βK = 0 and that this is the\n",
    "only meaningful value so that Eq. (1) holds also for i = K.\n",
    "• Show that because of this choice for βK, wen can merge Eq. (2) and (3) to\n",
    "for all i ∈ {1, .., K}, i.e. do not have to treat class K specifically"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 2\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will now explicitly expand our learner models to deliver probabilistic predictions. Besides the train(X,y) function, they should now implement a function\n",
    "getProbabilities(X), which should return a n × K numpy array, where an n is the number\n",
    "of instances in X and K is the number of labels in the considered problem. In this output\n",
    "array, the cell (i,j) is the probability the model assigned to instance i to belong to class j.\n",
    "\n",
    "Write a learner Logistic that builds models for multi-class classification problems according\n",
    "to the algorithm seen in the lecture. Use parameters step_size, eps (for the cancellation\n",
    "criterion ε, and max_iter for the maximum number of steps."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Logistic:\n",
    "    def __init__(self, _step_size=5, _eps=0.95, _max_iter=100):\n",
    "        self._step_size = _step_size\n",
    "        self._eps = _eps\n",
    "        self.max_iter = _max_iter\n",
    "    def train(self,_X,_Y):\n",
    "        pass\n",
    "    def predict(self,_X):\n",
    "        pass\n",
    "    def getProbabilites(self,_X):\n",
    "        pass\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "39615471a12bbabdc24952a6b2334f200eb09c18349abce2bd8427685dd9b8c6"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit (system)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}